# -*- coding: utf-8 -*-
"""DBDA.X408_Week_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rB1xsYvWZ4Z-peFHJE1zahK9LTCSvwx9

# Using sklearn to see pruning effect on trees
"""



import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier

X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

"""![image.png](data:image/png;base64,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)"""

clf = DecisionTreeClassifier()
path = clf.cost_complexity_pruning_path(X_train, y_train)
path

ccp_alphas, impurities = path.ccp_alphas, path.impurities

plt.figure(figsize=(10, 6))
plt.plot(ccp_alphas, impurities)
plt.xlabel("effective alpha")
plt.ylabel("total impurity of leaves")

"""Finding an optimal value of alpha using Python"""

clfs = []

for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

"""As we already know that there is a strong relation between, alpha and the depth of the tree. We can find the relation using this plot."""

tree_depths = [clf.tree_.max_depth for clf in clfs]
plt.figure(figsize=(10,  6))
plt.plot(ccp_alphas[:-1], tree_depths[:-1])
plt.xlabel("effective alpha")
plt.ylabel("total depth")

"""Use the following code to find the relation between alpha and accuracy."""

from sklearn.metrics import accuracy_score

acc_scores = [accuracy_score(y_test, clf.predict(X_test)) for clf in clfs]

tree_depths = [clf.tree_.max_depth for clf in clfs]
plt.figure(figsize=(10,  6))
plt.grid()
plt.plot(ccp_alphas[:-1], acc_scores[:-1])
plt.xlabel("effective alpha")
plt.ylabel("Accuracy scores")

"""We can clearly see that somewhere around 0.013 alpha, we get a very good value of accuracy."""



"""# Tuning randomization in sklearn.ensemble"""

from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor
from sklearn.model_selection import ShuffleSplit, validation_curve

import numpy as np

# Validation of max_features, controlling randomness in forests
param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]

_, test_scores = validation_curve(
    RandomForestRegressor(n_estimators=100, n_jobs=-1),
    X,
    y,
    cv=ShuffleSplit(n_splits=10, test_size=0.25),
    param_name="max_features",
    param_range=param_range,
    scoring="neg_mean_squared_error")

test_scores_mean = np.mean(-test_scores, axis=1)
plt.plot(param_range, test_scores_mean, label="RF", color="g")

_, test_scores = validation_curve(
    ExtraTreesRegressor(n_estimators=100, n_jobs=-1),
    X,
    y,
    cv=ShuffleSplit(n_splits=10, test_size=0.25),
    param_name="max_features",
    param_range=param_range,
    scoring="neg_mean_squared_error")

test_scores_mean = np.mean(-test_scores, axis=1)
plt.plot(param_range, test_scores_mean, label="ETs", color="r")

plt.show()
print("MSE vs Max_features")



"""# Careful tunning required for GBRT"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import ShuffleSplit, validation_curve, GridSearchCV
from sklearn.datasets import load_wine

X, y = load_wine(return_X_y=True)

# Careful tuning is required to obtained good results
param_grid = {
    "loss": ["mse", "lad", "huber"],
    "learning_rate": [0.1, 0.01, 0.001],
    "max_depth": [3, 5, 7],
    "min_samples_leaf": [1, 3, 5],
    "subsample": [1.0, 0.9, 0.8]
}

est = GradientBoostingRegressor(n_estimators=1000)

grid = GridSearchCV(
    est,
    param_grid,
    cv=ShuffleSplit(n_splits=10, test_size=0.25),
    scoring="neg_mean_squared_error",
    n_jobs=-1).fit(X, y)

gbrt = grid.best_estimator_

y

gbrt

"""# Variable importances"""

import pandas as pd
from sklearn.datasets import load_wine

X, y = load_wine(return_X_y=True)
importances = pd.DataFrame()

feature_names = [
    "Alcohol",
    "Malic acid",
    "Ash",
    "Alcalinity of ash",
    "Magnesium",
    "Total phenols",
    "Flavanoids",
    "Nonflavanoid phenols",
    "Proanthocyanins",
    "Color intensity",
    "Hue",
    "OD280/OD315 of diluted wines",
    "Proline"
]

# Variable importances with Random Forest, default parameters
est = RandomForestRegressor(n_estimators=10000, n_jobs=-1).fit(X, y)
importances["RF"] = pd.Series(est.feature_importances_, index=feature_names)

# Variable importances with Totally Randomized Trees
est = ExtraTreesRegressor(max_features=1, max_depth=3,
n_estimators=10000, n_jobs=-1).fit(X, y)
importances["TRTs"] = pd.Series(est.feature_importances_, index=feature_names)

# Variable importances with GBRT
importances["GBRT"] = pd.Series(gbrt.feature_importances_, index=feature_names)

importances.plot(kind="barh")

"""# Perceptron"""

from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler

X, y = make_blobs(n_samples = 500, centers = 2, n_features = 2, random_state=7)

"""Using the `StandardScaler()` method provided in sklearn library, we can scale the data to a range to reduce the computational complexity and to provide equal contribution for each feature to determine the decision boundary."""

scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)

import matplotlib.pyplot as plt

plt.title("Plot of dataset")
plt.scatter(X[:, 0], X[:, 1], c=y)

"""Let’s add few more points that challenges Perceptron, and without violating the non-linearity of the data."""

import numpy as np

a = np.array([[0.5,2]])
b = np.array([0])
X =np.concatenate((X, a))
y = np.concatenate((y, b))

plt.title("Plot of dataset (with new point)")
plt.scatter(X[:, 0], X[:, 1], c=y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=290)
plt.title("Plot of training split")
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)

plt.title("Plot of testing split")
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)

"""Perceptron learning"""

from sklearn.linear_model import Perceptron
from sklearn.model_selection import cross_val_score

#Creating a classifier
classifier = Perceptron(max_iter=100, eta0=0.1, random_state=0)

#Training the model using classifier
classifier.fit(X_train, y_train)

#Getting cross validation score to predict the model accuracy
scores = cross_val_score(classifier, X_train, y_train, cv=5)
print("Accuracy: %0.4f (+/- %0.4f)" % (scores.mean(), scores.std() * 2))

"""Plot the boundary"""

plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30)
ax = plt.gca()
plt.title("Plot of decision boundary on training split")

xlim = ax.get_xlim()
ylim = ax.get_ylim()

# create grid to evaluate model
xx = np.linspace(xlim[0], xlim[1], 30)
yy = np.linspace(ylim[0], ylim[1], 30)
YY, XX = np.meshgrid(yy, xx)
xy = np.vstack([XX.ravel(), YY.ravel()]).T
Z = classifier.decision_function(xy).reshape(XX.shape)

# plot decision boundary and margins
ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1, linestyles=['-'])

"""Now let's see prediction on testing set."""

from sklearn import metrics

y_pred = classifier.predict(X_test)

print("Accuracy: %0.4f"% metrics.accuracy_score(y_test, y_pred))

plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=30)
ax = plt.gca()
plt.title("Plot of decision boundary on testing split")

xlim = ax.get_xlim()
ylim = ax.get_ylim()

# create grid to evaluate model
xx = np.linspace(xlim[0], xlim[1], 30)
yy = np.linspace(ylim[0], ylim[1], 30)
YY, XX = np.meshgrid(yy, xx)
xy = np.vstack([XX.ravel(), YY.ravel()]).T
Z = classifier.decision_function(xy).reshape(XX.shape)

# plot decision boundary and margins
ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1, linestyles=['-'])

"""We are get the accuracy of 0.9802. This means, the data being linearly separable, Perceptron is not able to properly classify the data out of the sample.

Compare with SVM
"""

from sklearn import svm

#Creating a classifier
classifier = svm.SVC(kernel="linear")

#Training the model using classifier
classifier.fit(X_train, y_train)

#Getting cross validation score to predict the model accuracy
scores = cross_val_score(classifier, X_train, y_train, cv=5)

print("Accuracy: %0.4f (+/- %0.4f)" % (scores.mean(), scores.std() * 2))

y_pred = classifier.predict(X_test)
print("Accuracy: %0.4f"% metrics.accuracy_score(y_test, y_pred))

# obtain the suport vectors
decision_function = classifier.decision_function(X_train)

support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]
support_vectors = X_train[support_vector_indices]

plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=30)
ax = plt.gca()
plt.title("Plot of decision boundary on testing split for SVM")

xlim = ax.get_xlim()
ylim = ax.get_ylim()

from sklearn.inspection import DecisionBoundaryDisplay

DecisionBoundaryDisplay.from_estimator(
    classifier,
    X_train,
    ax=ax,
    grid_resolution=50,
    plot_method="contour",
    colors="k",
    levels=[-1, 0, 1],
    alpha=0.5,
    linestyles=["--", "-", "--"],
)

plt.show()



"""# Neural Network

We demonstrate neural networks using artificial color spiral data. This is a 2-D dataset where different points are colored differently, and the task is to predict the correct color based on the point location. So it is a basic decision task. However, in order to make the task reasonably complex, we introduce the colors in a spiral pattern. We create the data as follows:
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

n = 800  # number of data points
x1 = np.random.normal(size=n)
x2 = np.random.normal(size=n)

X = np.column_stack((x1, x2))  # design matrix

alpha = np.arctan2(x2, x1)

r = np.sqrt(x1**2 + x2**2)
c1 = np.sin(3*alpha + 2*r)
c2 = np.cos(3*alpha + 2*r)

## partition the sum of a sin and cosine into 5 intervals
category = pd.cut(c1 + c2,
           bins=[-1.5, -1.1, -0.6, 0.6, 1.1, 1.5],
           labels=[1, 2, 3, 4, 5])
y = category.astype(int)

set(y)

from collections import Counter

plt.figure(figsize=(8,8))
ax = plt.axes()
points = ax.scatter(X[:,0], X[:,1], c=y, s=40, edgecolors='black')
ax.set_aspect("equal")
handles, _ = points.legend_elements()
labels =sorted([f'{item}: {count}' for item, count in Counter(y).items()])
ax.legend(handles, labels, loc = "lower right",title = 'clusters')
plt.show()

"""sklearn implements simple feed-forward neural networks, multi-layer perceptrons.

Let us now demonstrate the usage of MLPClassifier on the color spiral image data. Let us start with a simple perceptron with a single hidden layer of 20 nodes.
"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix

m = MLPClassifier(hidden_layer_sizes = (20,), max_iter=10000)
_ = m.fit(X, y)
yhat = m.predict(X)
confusion_matrix(y, yhat)

np.mean(yhat == y)

"""This is because it is too simple, just a single small hidden layer is not enough to model the complex spiral pattern well. Let’s also check to decision boundary plot to see how does the model represent the image:"""

def DBPlot(m, X, y, nGrid = 100):
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, nGrid),
                           np.linspace(x2_min, x2_max, nGrid))
    XX = np.column_stack((xx1.ravel(), xx2.ravel()))
    hatyy = m.predict(XX).reshape(xx1.shape)
    plt.figure(figsize=(8,8))
    _ = plt.imshow(hatyy, extent=(x1_min, x1_max, x2_min, x2_max),
                   aspect="auto",
                   interpolation='none', origin='lower',
                   alpha=0.3)
    plt.scatter(X[:,0], X[:,1], c=y, s=30, edgecolors='k')
    plt.xlim(x1_min, x1_max)
    plt.ylim(x2_min, x2_max)
    plt.show()

DBPlot(m, X, y)

"""We can see that the model correctly captures the idea: spirals of different colors, but the shape of spirals is not accurate enough.

Let us repeat the model with a more powerful network:
"""

m = MLPClassifier(hidden_layer_sizes = (256, 128, 64), max_iter=10000)
_ = m.fit(X, y)

yhat = m.predict(X)
confusion_matrix(y, yhat)

np.mean(yhat == y)

DBPlot(m, X, y)

"""A visual inspection confirms that the more powerful neural network is quite good in capturing the overall model structure.

# Using Tensorflow with Keras
"""

import tensorflow as tf
import tensorflow_datasets as tfds

"""## Load a dataset
Load the MNIST dataset with the following arguments:

- `shuffle_files=True`: The MNIST data is only stored in a single file, but for larger datasets with multiple files on disk, it's good practice to shuffle them when training.
- `as_supervised=True`: Returns a tuple `(img, label)` instead of a dictionary `{'image': img, 'label': label}`.
"""

(ds_train, ds_test), ds_info = tfds.load(
    'mnist',
    split=['train', 'test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True,
)

"""## Build a training pipeline
Apply the following transformations:

- `tf.data.Dataset.map`: TFDS provide images of type `tf.uint8`, while the model expects `tf.float32`. Therefore, you need to normalize images.
-` tf.data.Dataset.cache` As you fit the dataset in memory, cache it before shuffling for a better performance.
Note: Random transformations should be applied after caching.
- `tf.data.Dataset.shuffle`: For true randomness, set the shuffle buffer to the full dataset size.
Note: For large datasets that can't fit in memory, use buffer_size=1000 if your system allows it.
- `tf.data.Dataset.batch`: Batch elements of the dataset after shuffling to get unique batches at each epoch.
- `tf.data.Dataset.prefetch`: It is good practice to end the pipeline by prefetching for performance.

Similiarly doing the testing, but no need shuffle.
"""

ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_test = ds_test.batch(128)
ds_test = ds_test.cache()
ds_test = ds_test.prefetch(tf.data.AUTOTUNE)

"""Setup and compile model

The three most important arguments are

- `loss` describes the model loss function, `sparse_categorical_crossentropy`, essentially log-likelihood, is suitable for categorization tasks. The exact type also depends on how exactly is the outcome coded.
- `optimizer` is the optimizer to use for stochastic gradient descent. `adam` and `rmsprop` are good choices but there are other options.
- `metrics` is a metric to be evaluated and printed while optimizing, offering some feedback about how the evaluation is going.

"""

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10)
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)

history = model.fit(
    ds_train,
    epochs=6,
    validation_data=ds_test,
)

print(model.summary())

history.history

print("Evaluate on test data")
results = model.evaluate(ds_test, batch_size=10)
print("test loss, test acc:", results)

p_hat = model.predict(ds_test)

p_hat[:1]

y_hat = np.argmax(p_hat, axis=-1)
y_hat[:5]

